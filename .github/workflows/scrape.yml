name: Palantir Sentiment Analysis

on:
  schedule:
    - cron: '*/30 * * * *'
  
  workflow_dispatch:
    inputs:
      debug:
        description: 'Enable debug logging'
        required: false
        default: false
        type: boolean

  # Run on push to main for testing (remove in production)
  push:
    branches: [ main ]
    paths:
      - 'backend/**'
      - '.github/workflows/scrape.yml'

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up environment variables
      run: |
        echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
        echo "SUPABASE_SERVICE_KEY=${{ secrets.SUPABASE_SERVICE_KEY }}" >> $GITHUB_ENV
        if [[ "${{ github.event.inputs.debug }}" == "true" ]]; then
          echo "DEBUG=true" >> $GITHUB_ENV
        fi
    
    - name: Run sentiment analysis
      working-directory: ./backend
      run: |
        if [[ "$DEBUG" == "true" ]]; then
          python -v scraper.py
        else
          python scraper.py
        fi
      env:
        PYTHONPATH: ${{ github.workspace }}/backend
        PYTHONUNBUFFERED: 1
    
    - name: Health check
      if: always()  # Run even if previous step fails
      working-directory: ./backend
      run: |
        python -c "
        from supabase_client import SupabaseClient
        import json
        
        try:
            client = SupabaseClient()
            health = client.get_health_status()
            print('Health Status:')
            print(json.dumps(health, indent=2))
            
            if health.get('status') != 'healthy':
                print('⚠️ Health check indicates issues')
            else:
                print('✅ System healthy')
        except Exception as e:
            print(f'❌ Health check failed: {e}')
            exit(1)
        "
    
    - name: Cleanup old data (weekly)
      # Only run cleanup on Sundays at midnight
      if: github.event.schedule == '15 0 * * 0'
      working-directory: ./backend
      run: |
        python -c "
        from supabase_client import SupabaseClient
        
        try:
            client = SupabaseClient()
            client.cleanup_old_data(days=30)
            print('✅ Cleanup completed')
        except Exception as e:
            print(f'❌ Cleanup failed: {e}')
        "
    
    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const issue_title = `🚨 Sentiment Analysis Failed - ${new Date().toISOString().split('T')[0]}`;
          const issue_body = `
          ## Scraping Job Failed
          
          **Workflow:** ${context.workflow}
          **Run ID:** ${context.runId}
          **Commit:** ${context.sha}
          **Branch:** ${context.ref}
          **Actor:** ${context.actor}
          
          **Logs:** [View Run](${context.payload.repository.html_url}/actions/runs/${context.runId})
          
          Please check the logs and fix the issue.
          
          ---
          *This issue was automatically created by GitHub Actions*
          `;
          
          // Check if there's already an open issue for today
          const today = new Date().toISOString().split('T')[0];
          const { data: issues } = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'automated,scraping-failure',
            per_page: 10
          });
          
          const existingIssue = issues.find(issue => 
            issue.title.includes(today) && issue.title.includes('Sentiment Analysis Failed')
          );
          
          if (!existingIssue) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: issue_title,
              body: issue_body,
              labels: ['automated', 'scraping-failure', 'bug']
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: existingIssue.number,
              body: `Another failure occurred at ${new Date().toISOString()}\n\n[View Run](${context.payload.repository.html_url}/actions/runs/${context.runId})`
            });
          }

  # Optional: Test job that runs on PR
  test-scraper:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Test imports and basic functionality
      working-directory: ./backend
      run: |
        python -c "
        # Test imports
        from scraper import PalantirSentimentAnalyzer
        from supabase_client import SupabaseClient
        from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
        
        # Test VADER
        analyzer = SentimentIntensityAnalyzer()
        test_sentiment = analyzer.polarity_scores('Palantir is doing great!')
        assert 'compound' in test_sentiment
        
        print('✅ All imports successful')
        print('✅ VADER analyzer working')
        print('✅ Basic functionality test passed')
        " 